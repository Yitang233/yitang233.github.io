---
title: "Long as a Tale: Unlocking Long-Video Context in VLMs with Hour-long Data"
collection: publications
category: manuscripts
permalink: /publication/2024-long-as-a-tale
excerpt: "Hour-long video pipeline and long-context VLM training/evaluation up to 224K tokens and 1,200 frames; in preparation."
date: 2024-08-01
venue: "In preparation"
slidesurl: 
paperurl: "files/long-as-a-tale.pdf"
citation: "Gao, Y. (2024). Long as a Tale: Unlocking Long-Video Context in VLMs with Hour-long Data. In preparation."
---
Hour-long video data pipeline built with taxonomy-driven retrieval and three-stage filtering to curate ~4.5K videos (20–60 min). Subtitle-to-description generation, long-context training with RoPE θ=10^9, and evaluation across Video-MME, V-NIAH, MLVU, and LVBench (reported +6.0 long, +5.8 medium, +0.7 short on Video-MME; +3.4 MLVU; +4.6 LVBench).
